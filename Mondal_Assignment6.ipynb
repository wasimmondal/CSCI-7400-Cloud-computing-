{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vXNGz8L1it6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\">Installing pyspark.</font>    "
      ],
      "metadata": {
        "id": "jY_7-BZ9ivZW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXizzTYzbiNe",
        "outputId": "453c9f38-b9c2-4465-d4a6-b0fa6179c732"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.5)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.11/dist-packages (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark py4j"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "IK5IgahHK63w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "iK9StdzUzQWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\"> Importing SparkSession class </font> <br>\n",
        "<font color=\"blue\"> SparkSession.builder create a builder object to configure SparkSession </font> <br>\n",
        "<font color=\"blue\"> .master(\"local[*]\") set the master URL to local so that Spark run locally</font> <br>\n",
        "<font color=\"blue\"> .getOrCreate If one spark session exist, use that , if not create a new one</font> <br>"
      ],
      "metadata": {
        "id": "SD57gN7ZzSqP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
      ],
      "metadata": {
        "id": "1502Rm7tc6Dn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\"> Uploading the text data file. Colab does not save. So, we have to upload every time. We can keep the file saved in Google drive </font> <br>"
      ],
      "metadata": {
        "id": "I45CYGb91e1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "rdd_data =files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "RvZsY7Qvemto",
        "outputId": "00d91782-0cd7-48ae-a1d1-c0c13a28e319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-29576241-3f38-4676-839e-78db4336c659\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-29576241-3f38-4676-839e-78db4336c659\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving rdd_data to rdd_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\"> It is in older version. Retriving the underlying SparkContext from active Spark session.      </font>"
      ],
      "metadata": {
        "id": "0hP6yxBv3moK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sc = spark.sparkContext"
      ],
      "metadata": {
        "id": "Pj7S738on59h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\"> Reading the text file from the path into a RDD     </font>"
      ],
      "metadata": {
        "id": "a_Ja6MqV7TUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RDD = sc.textFile(\"/content/rdd_data\")"
      ],
      "metadata": {
        "id": "qXgYuLeVoQOM",
        "outputId": "bc0068bc-8624-4dcb-830f-1c69a6259f33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'sc' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-db46d3d47471>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mRDD\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtextFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/rdd_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sc' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\"> Taking the first five element in RDD. Confirming that text from the input file has taken sucesfully     </font>"
      ],
      "metadata": {
        "id": "jGWQYyM6-caY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "RDD.take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aNWFrxtioYQQ",
        "outputId": "414d9b51-d83c-4445-901e-559dd284d091"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this is an example of spark',\n",
              " 'the example contains several lines',\n",
              " 'spark has low level and high level api']"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\"> 1. What would rdd_split contain? Explain your answer </font> <br>"
      ],
      "metadata": {
        "id": "IlTJguAOUJ2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\"> As shown above, first it is taking RDD as string corresponding to each line and stores them in a list. For example, here are three lines. So, we have three string in a list as shown above </font> <br>\n",
        "<font color=\"blue\"> Then, it is splitting each line into words using space as delimeter and stores them in the list.</font> <br>\n",
        "<font color=\"blue\"> So, the rdd_split contains a list of words as displayed below:</font> <br>"
      ],
      "metadata": {
        "id": "23m_zXQOAPPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_split = rdd_data.flatMap(lambda element: element.split(\" \"))"
      ],
      "metadata": {
        "id": "A5YIY0_mshdX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\"> Returns all elements of the RDD to the driver program as python list </font> <br>.\n",
        "<font color=\"blue\"> Here RDD size is small. So, we can use it with no worries. But if the RDD is very large, it can crash. So, we have to careful before using it </font> <br>."
      ],
      "metadata": {
        "id": "8YXZG-9qGQNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_split.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00Bh0HEVsxeG",
        "outputId": "1ba25afc-49a3-4d28-fe15-e91b19063fac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['this',\n",
              " 'is',\n",
              " 'an',\n",
              " 'example',\n",
              " 'of',\n",
              " 'spark',\n",
              " 'the',\n",
              " 'example',\n",
              " 'contains',\n",
              " 'several',\n",
              " 'lines',\n",
              " 'spark',\n",
              " 'has',\n",
              " 'low',\n",
              " 'level',\n",
              " 'and',\n",
              " 'high',\n",
              " 'level',\n",
              " 'api']"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\"> 2. What would rdd_map contain? Explain your answer. </font> <br>"
      ],
      "metadata": {
        "id": "t4VV9zgSWW2z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\"> First, it is creating key value pair for word counting and then assigin that count number with the word in tuple. </font> <br>.\n",
        "<font color=\"blue\"> So, rdd_map will contain many tuples with key value(count) pair in a list as displayed below. For example, tuple of 'example with 1 count displayed 2 times as two different tuple. </font> <br>."
      ],
      "metadata": {
        "id": "z1wjpRfoH40d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_map = rdd_split.map(lambda element: (element,1))"
      ],
      "metadata": {
        "id": "qUt25rPstnef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_map.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_U9tulytqu5",
        "outputId": "2e3bb62d-c695-4870-ee62-e665a5b5304f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('this', 1),\n",
              " ('is', 1),\n",
              " ('an', 1),\n",
              " ('example', 1),\n",
              " ('of', 1),\n",
              " ('spark', 1),\n",
              " ('the', 1),\n",
              " ('example', 1),\n",
              " ('contains', 1),\n",
              " ('several', 1),\n",
              " ('lines', 1),\n",
              " ('spark', 1),\n",
              " ('has', 1),\n",
              " ('low', 1),\n",
              " ('level', 1),\n",
              " ('and', 1),\n",
              " ('high', 1),\n",
              " ('level', 1),\n",
              " ('api', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\"> 3. What would rdd_reduce contain? Explain your answer. Explain your answer. </font> <br>"
      ],
      "metadata": {
        "id": "MvB-Mmxae7Wg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\"> It takes RDD as key value pair as rdd_map and sums values for identical keys using lambda function. So, rdd_reduce contain tuples with key as word and total count value of that word as value. For example, the tuple having 'example' has values 2 because they are counted as 2.  Alll these tuples are inside a single list.  </font> <br>."
      ],
      "metadata": {
        "id": "jAPO4T5GJyek"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_reduce = rdd_map.reduceByKey(lambda x,y: x+y)"
      ],
      "metadata": {
        "id": "KRe_UkPCtvTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_reduce.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZjSQQMCt1ma",
        "outputId": "94a0fc3e-9220-4492-8d42-17769f79fa6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('this', 1),\n",
              " ('an', 1),\n",
              " ('of', 1),\n",
              " ('lines', 1),\n",
              " ('low', 1),\n",
              " ('level', 2),\n",
              " ('and', 1),\n",
              " ('high', 1),\n",
              " ('api', 1),\n",
              " ('is', 1),\n",
              " ('example', 2),\n",
              " ('spark', 2),\n",
              " ('the', 1),\n",
              " ('contains', 1),\n",
              " ('several', 1),\n",
              " ('has', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\"> 4. What would rdd_filter contain? Explain your answer. Explain your answer. </font> <br>"
      ],
      "metadata": {
        "id": "7if8H-kxfykb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\"> It filters an RDD of key, value pairs to keep only entries where the key contains the letter 'r'. So, rdd_filter contains list of tuples where tuples with word as key with their totla counting values and these words are only the words which has \"r\"    </font> <br>."
      ],
      "metadata": {
        "id": "ZtWG-2qRKuBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_filter = rdd_reduce.filter(lambda element: 'r' in element[0])"
      ],
      "metadata": {
        "id": "iRvhbl1Nt_ne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\"> The key spark and several has been filtered because these key contains the letter 'r'   </font> <br>."
      ],
      "metadata": {
        "id": "IU7RmUzBLmd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rdd_filter.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KBGSIs1QuMEd",
        "outputId": "3c1610f7-a599-4b6a-bc17-122f4a21102f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('spark', 2), ('several', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\"> 5. What is the output of the above operation? Explain your answer.  </font> <br>"
      ],
      "metadata": {
        "id": "K6qhmeOXglDl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\"> Here split(\" \") converts the string into a list. we note that split(\" \") behaves differently than split()</font> <br>.\n",
        "<font color=\"blue\"> split(\" \") For example, \"a b\".split(\" \") creates [\"a\", \" \", \"b\"]</font> <br>.\n",
        "<font color=\"blue\"> split(\" \") For example, \"a b\".split() creates [\"a\", \"b\"]</font> <br>.\n",
        "<font color=\"blue\"> By parallelize(myData,2) RDD is created with two partions: partion 0 and partion 1   \n",
        " </font> <br>.\n",
        " <font color=\"blue\"> In first partion , we have partion 0: [\"resilient\", \"datasets\"] and in the second partion we have  partion 1: [\"distributed\"]    \n",
        " </font> <br>.\n",
        " <font color=\"blue\"> So, the final output will be list of each words as shown below    \n",
        " </font> <br>."
      ],
      "metadata": {
        "id": "-2dm2zrDMyu5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "myData = \"resilient distributed datasets\".split(\" \")\n",
        "data=sc.parallelize(myData,2)\n",
        "data.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4G-e6BrxfOK",
        "outputId": "a7d1223c-19b7-4380-e6db-f549fcb35c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['resilient', 'distributed', 'datasets']"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\"> 6. What is the output of the above operation? Explain your answer. </font> <br>"
      ],
      "metadata": {
        "id": "nyX7XnZWiF6y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\"> distinctOut = data.distinct(): It is transformation. It creates a new RDD containing unique elements from the original data RDD</font> <br>.\n",
        "<font color=\"blue\"> distinctOut.count triggers an action to compute the number of unqiue elements. There are 3 unique elemnts as resilient, distributed and datasets. So, output will be 3 as shown below:</font> <br>."
      ],
      "metadata": {
        "id": "xKRTL4QYPkTU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distinctOut=data.distinct()\n",
        "distinctOut.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXUIyfxextCY",
        "outputId": "41362db4-61ac-4db9-d117-600eb274e755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"red\"> 7.  What is the output of the above operation? Explain your answer. </font> <br>"
      ],
      "metadata": {
        "id": "Exh1AEIPivzq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\"> element.startwith (\"d\"): Boolean flag for elements starting with \"d\"</font> <br>.\n",
        "<font color=\"blue\"> element[0]:First character</font> <br>.\n",
        "<font color=\"blue\"> so the mapping phase creates tuple with three elements (word as element, First character of that word, boolenan value) and a single list will hold these tuples. So, the final output will be a single list containning tuples of word, their first character and bollen values.</font> <br>."
      ],
      "metadata": {
        "id": "8jkrE6G1RkQU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"blue\"> Filter phase filters the record where third tuple element is true. So, in the final output those tuples will be displayed where boolen value is true. For example, tuples for distributed and datasets have filtered out because their boolen value is True having d as first character.</font> <br>."
      ],
      "metadata": {
        "id": "7leTpy_fTPkh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataMap=data.map(lambda element: (element, element[0], element.startswith(\"d\")))\n",
        "dataMap.filter(lambda record: record[2]).take(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5oo7uvnayHg6",
        "outputId": "2ee257f6-a5fd-4a06-85ca-9d1be78e4f14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('distributed', 'd', True), ('datasets', 'd', True)]"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pCo8xndEknRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "itW_DYkIySU1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}